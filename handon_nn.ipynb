{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 84,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"mnist_train.csv\")\n",
    "X = data.drop(\"label\",axis=1).values\n",
    "y = data[\"label\"].values\n",
    "# normalization X\n",
    "X = X / 255.\n",
    "# transpose\n",
    "X = X.T"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "outputs": [],
   "source": [
    "def init_parameter():\n",
    "    W1 = np.random.rand(10,784) - 0.5\n",
    "    b1 = np.random.rand(10,1) - 0.5\n",
    "    W2 = np.random.rand(10,10) - 0.5\n",
    "    b2 = np.random.rand(10,1) - 0.5\n",
    "    return W1, b1, W2, b2\n",
    "\n",
    "def ReLU(Z):\n",
    "    return np.maximum(Z, 0)\n",
    "\n",
    "\n",
    "def Softmax(Z):\n",
    "    A = np.exp(Z) / sum(np.exp(Z))\n",
    "    return A\n",
    "\n",
    "\n",
    "def forward_prop(W1, b1, W2, b2, X):\n",
    "    Z1 = W1.dot(X) + b1\n",
    "    A1 = ReLU(Z1)\n",
    "\n",
    "    Z2 = W2.dot(A1) +b2\n",
    "    A2 = Softmax(Z2)\n",
    "\n",
    "\n",
    "    return Z1, A1, Z2, A2\n",
    "\n",
    "def onehot_encoder(y):\n",
    "    encode = np.zeros((y.size,y.max() + 1))\n",
    "    encode[np.arange(y.size), y] = 1\n",
    "    encode = encode.T\n",
    "    return encode\n",
    "\n",
    "def ReLU_deriv(Z):\n",
    "    return Z > 0\n",
    "\n",
    "def back_prop(Z1, A1, Z2, A2, W1, b1, W2, b2, X, y):\n",
    "    n, m = X.shape\n",
    "    y_one_hot = onehot_encoder(y)\n",
    "\n",
    "    # dZ4 = A4 - y_one_hot\n",
    "    # dW4 = 1 / m * dZ4.dot(A3.T)\n",
    "    # db4 = 1 / m * np.sum(dZ4)\n",
    "\n",
    "    # dZ3 = W4.T.dot(dZ4) * ReLU_deriv(Z3)\n",
    "    # dZ3 = A3 - y_one_hot\n",
    "    # dW3 = 1 / m * dZ3.dot(A2.T)\n",
    "    # db3 = 1 / m * np.sum(dZ3)\n",
    "\n",
    "    # dZ2 = W3.T.dot(dZ3) * ReLU_deriv(Z2)\n",
    "    dZ2 = A2 - y_one_hot\n",
    "    dW2 = 1 / m * dZ2.dot(A1.T)\n",
    "    db2 = 1 / m * np.sum(dZ2)\n",
    "\n",
    "    dZ1 = W2.T.dot(dZ2) * ReLU_deriv(Z1)\n",
    "    dW1 = 1 / m * dZ1.dot(X.T)\n",
    "    db1 = 1 / m * np.sum(dZ1)\n",
    "    return dW1, db1, dW2, db2\n",
    "\n",
    "def update_params(W1, b1, W2, b2, dW1, db1, dW2, db2, alpha):\n",
    "    W1 = W1 - alpha * dW1\n",
    "    b1 = b1 - alpha * db1\n",
    "    W2 = W2 - alpha * dW2\n",
    "    b2 = b2 - alpha * db2\n",
    "    return W1, b1, W2, b2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "outputs": [],
   "source": [
    "def get_prediction(A):\n",
    "    return np.argmax(A, 0)\n",
    "\n",
    "def get_acc(predict, y):\n",
    "    return np.sum(predict == y) / y.size\n",
    "\n",
    "def gradient_descent(X, y, alpha, epochs):\n",
    "    W1, b1, W2, b2, = init_parameter()\n",
    "    for epoch in range(epochs):\n",
    "        Z1, A1, Z2, A2,  = forward_prop(W1, b1, W2, b2, X)\n",
    "        dW1, db1, dW2, db2 = back_prop(Z1, A1, Z2, A2, W1, b1, W2, b2, X, y)\n",
    "        W1, b1, W2, b2,  = update_params(W1, b1, W2, b2, dW1, db1, dW2, db2, alpha)\n",
    "        if epoch % 50 == 0:\n",
    "            print(\"Epochs:\", epoch)\n",
    "            predict = get_prediction(A2)\n",
    "            print(get_acc(predict,y))\n",
    "    return W1, b1, W2, b2, W3, b3"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 0\n",
      "0.10845\n",
      "Epochs: 50\n",
      "0.11328333333333333\n",
      "Epochs: 100\n",
      "0.11708333333333333\n",
      "Epochs: 150\n",
      "0.12138333333333333\n",
      "Epochs: 200\n",
      "0.12538333333333335\n",
      "Epochs: 250\n",
      "0.12903333333333333\n",
      "Epochs: 300\n",
      "0.13281666666666667\n",
      "Epochs: 350\n",
      "0.13728333333333334\n",
      "Epochs: 400\n",
      "0.1426\n",
      "Epochs: 450\n",
      "0.14731666666666668\n",
      "Epochs: 500\n",
      "0.1521\n",
      "Epochs: 550\n",
      "0.157\n",
      "Epochs: 600\n",
      "0.16111666666666666\n",
      "Epochs: 650\n",
      "0.16478333333333334\n",
      "Epochs: 700\n",
      "0.16895\n",
      "Epochs: 750\n",
      "0.17223333333333332\n",
      "Epochs: 800\n",
      "0.17576666666666665\n",
      "Epochs: 850\n",
      "0.17898333333333333\n",
      "Epochs: 900\n",
      "0.18271666666666667\n",
      "Epochs: 950\n",
      "0.188\n"
     ]
    }
   ],
   "source": [
    "W1, b1, W2, b2, W3, b3 = gradient_descent(X, y, 0.001, 1000)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}